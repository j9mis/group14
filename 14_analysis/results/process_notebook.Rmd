---
title: "Final Project Analysis"
author: "Group 14"
date: "5/4/2017"
output: 
    html_document:
        toc: true
        toc_float: true
        code.folding: hide 
---
```{r setup, warning=FALSE, message=F, echo=FALSE}
library(jsonlite)
library(stringr)
library(tidyverse)
library(readr)
library(knitr)

data <- read_csv('14_data_3.csv')
```


# Abstract 
One paragraph at the very beginning of the document summarizing everything.
```{r}

```

***

# Overview and Motivation 
Provide an overview of the project goals and the motivation for it. Consider that this will be read by people who did not see your project proposal.

In recent media, more and more time and reporting have been dedicated to the topic of police actions. In the recent years, one of the topics that has gained media coverage significantly is deaths at the hands of the US police. Due to this recent surge of interest people have begun to collect more and more data about those that have been killed by poilice, as well as the details surrounding the incident. One such data set has been gathered by The Guardian as a supplement to an ongoing news story they call "The Counted". This data set has information regarding every reported incident of a person that was killed by a police officer in the years 2015 and 2016. Due to time restrictions and cleanliness of the data, we decided to choose to work with the 2015 data set.      
 -  The data that The Guardian provided had information about the deceased, including their name, race, age, and location at death. We decided to take this data set, and add a sense of background to each incident by adding information about the mendian income, high school education rate, and demographic makeup of the area in which the incident occurred. This was done using the 2015 census data for the census tract that corresponded to the location in the data.    
 -  Because our data set was so limited, we did not feel comfortable performing statistical analysis. Instead, we thought it would be more interesting to create an application that allows a user to explore the data for themselves and see the different patterns that emerge. So with this data set we set our goal was to create a Shiny application that will allow a user to interact with our data frame and create a variety of visualizations with the data. We accomplished this by first exploring the data ourselves to find some plots that we thouught were interesting. We then allowed the Shiny application we created to have the functionality to be able to create these plots and more. Alongside the graph maker, the application also has the ablility to show a United States map that shows the locations of each incident. This map has the ability to filter out points based on user selection. This means a user can easily view those who was armed with a firearm at their death, or those who were classified as Hispanic, or just who was killed in July with a simple drop down selection menu.    
 -  We feel that this project has a strong sense of cultural significance. Police killings is a major issue that is in hot debate currently, and to create an unbiased application that allows a user to come to their own conclusions seems to be a worthwhile effort. 

***

# Related Work 
Anything that inspired you, such as a paper, a web site, or something we discussed in class.
```{r}

```

***

# Initial Questions 
What questions are you trying to answer? 
How did these questions evolve over the course of the project? 
What new questions did you consider in the course of your analysis? 

```{r}

```

***

# Data 

### Sources

* **[FiveThirtyEight](https://github.com/fivethirtyeight/data/tree/master/police-killings):**  
We origionally chose our topic after stumbling upon the police killings dataset in FiveThirtyEight's github repository, however, this dataset only contained data for half of 2015. 

* **[BuzzFeed](https://github.com/BuzzFeedNews/2015-12-fatal-police-shootings):**   
We used a dataset from Buzzfeed's github repositrory that they obtained from the Guardian, however, this dataset was missing data after December 6th. 

* **[The Guardian](https://www.theguardian.com/us-news/ng-interactive/2015/jun/01/about-the-counted)**   
We combined The Guardian's post December 7th data with out dataset. These last points were missing latitude and longidude variables, but we added them later.  


### APIs
We wanted to gether information about the locations in which people were killed by police in 2015, so we utilized a combination of APIs. The first two APIs gave us the county and census tract of each incident. We chose to use census information about each census tract rather than each county so that the information applied to a smaller area more specific to each incident. We imput state and county information to return our desired census data and then joined the results to our dataset by state, county, and census tract. 

#### Our APIs:   
* **[National Broadband Map Census API](https://www.broadbandmap.gov/developer/api/census-api-by-coordinates)**  
    + input latitude and longitude to return corresponding census tract  
* **[Google Maps API](https://developers.google.com/maps/documentation/geocoding/intro)**   
    + input address to return corresponding county  
* **[US Census API](https://www.census.gov/data/developers/data-sets/acs-5year.html)**     
    + input state and county to return census data 
    
### Cleanup 



```{r}

```

***

# Exploratory Data Analysis 
Since we focused on creating a way for people to interact with our data rather than making inferences or predictions, our analysis consisted of making some simple plots and calulatings descriptive statistics. The goal of our visualizations and Shiny App are to allow people to explore and interpret the data for themselves as we have done. 
```{r}

```


### Time 
The following plot shows the number of people killed by police during each month of 2015.  
There appears to be somewhat of a cycle in which the numer of deaths per month rises to a peak and then begins to decline before rising again. 
This could possibly be due to the nature of media coverage or the time of year. 
```{r, echo = FALSE}
# PLOT OF DEATHS PER MONTH
date_count <- data %>% group_by(month_num) %>% count()
ggplot(date_count) + 
    geom_line(aes(x=month_num, y=n), color="#FF9999") +
    geom_point(aes(x=month_num, y=n), stat = "identity") + 
    ggtitle('Police Killed by Police in 2015') +
    labs(x = 'Month', y = '# of people killed by police') + 
    theme(axis.line.x = element_line(color = "black", size=.1),
        axis.line.y = element_line(color="black", size = .1), 
          panel.background = element_blank()) +
    scale_x_discrete(limits=c("01", "02", "03", "04", "05", "06", "07", "08", "09", "10", "11", "12"),
                     labels=c("Jan","Feb","Mar","Apr","May","Jun", "Jul", "Aug", "Sep", "Oct", "Nov","Dec"))  
```

### Age & Gender

The graph below shows the age distribution of the US population. We see that a lot of the popopulation falls pretty evenly between ages 0 to 55. There are clusters from 15 to 30 and from 40 t0 55. The population declines steadily after age 55.  
<img src="http://www.randalolson.com/wp-content/uploads/pop_pyramid_grouped_annotated.png" width="700" height="350" />  
  
    
      
        
          
            
              
Looking at the following age distribution of people killed by police, we can see that is does not have the same general shape of the age distribution of the US popultion. The distribution is skewed, indicating that young adults are killed by police more than children, middle-aged people, and the elderly. From this graph, we also note how many more men are killed by police than women.  
  
```{r echo=FALSE, warning=FALSE}
# HISTOGRAM OF AGE AND GENDER
data_age <- na.omit(select(data,age,gender))
ggplot(data_age) + geom_histogram(aes(x=age, fill=gender), binwidth = 4,position="dodge") + scale_fill_manual(values=c("Female"="#CC6699", "Male"="#6699CC", "Non-conforming"="#CC99FF")) +
    ggtitle('Age Distribution of People Killed by Police') + labs(x = 'Age', y = '# of people killed') +
    theme(panel.background = element_blank(), 
          axis.line = element_line(colour = "black", size=.1))+
    scale_x_continuous(breaks=c(0,20, 40, 60, 80),
                       limits=c(0,90),
                       expand=c(0, 1)) +
    scale_y_continuous(breaks=c(0, 50, 100, 150),
                       limits=c(0, 150),
                       expand=c(0,0)) 
```

### Race 
```{r, echo=FALSE, warning=FALSE}
# FUNCTION TO TURN INTO PER MILLION COUNTS (NORMAILZES)
pop_2015 = 321418820

asian_share = 0.056
black_share = 0.133
hispanic_share = 0.176
native_share = 0.012
white_share = 0.616

per_million_counts <- function(race_count){
    race_count$per_million <- NA
    for (i in 1:nrow(race_count)){
        if (race_count$raceethnicity[i] == "Asian/Pacific Islander"){
            race_count$per_million[i] = ((race_count$n[race_count$raceethnicity=="Asian/Pacific Islander"])*1000000)/(pop_2015*asian_share)
        } else if (race_count$raceethnicity[i] == "Black"){
            race_count$per_million[i] =     ((race_count$n[race_count$raceethnicity=="Black"])*1000000)/(pop_2015*black_share)
        } else if (race_count$raceethnicity[i] == "Hispanic/Latino"){ 
            race_count$per_million[i] = ((race_count$n[race_count$raceethnicity=="Hispanic/Latino"])*1000000)/(pop_2015*hispanic_share)
        } else if (race_count$raceethnicity[i] == "Native American"){ 
            race_count$per_million[i] = 
                ((race_count$n[race_count$raceethnicity=="Native American"])*1000000)/(pop_2015*native_share)
        } else if (race_count$raceethnicity[i] == "White"){ 
            race_count$per_million[i] = ((race_count$n[race_count$raceethnicity=="White"])*1000000)/(pop_2015*white_share)
        } else race_count$per_million[i] = NA       
    }
    return(race_count)
}
```

```{r, echo=FALSE, results='asis'}
# KABBLE BY RACE
race_count <- data %>% group_by(raceethnicity) %>% count()
race_count %>% arrange(desc(n)) %>% kable(col.names = c("Race/Ethnicity","Number of Deaths"), caption="Number of People Killed by Police by Race/Ethnicity")
```



```{r, echo=FALSE, warning=FALSE}
# HISTOGRAM BY RACE PER MILLION
race_count <- per_million_counts(race_count)
# Make a histogram
ggplot(na.omit(race_count)) + geom_bar(aes(x=raceethnicity, y=per_million), stat = "identity", fill="#FF9999") + 
    theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1), axis.line = element_line(colour = "black", size=.1),
          panel.background = element_blank()) +
    ggtitle('People Killed by Police by Race/Ethnicity') +
    labs(x = 'Race/Ethnicity', y = '# killed (per million)')
```


```{r, echo=FALSE, results='asis'}
# KABBLE ARMED BY RACE
race_count_armed <- data %>% filter(is_armed==0) %>% group_by(raceethnicity) %>% count()
race_count_armed %>% arrange(desc(n)) %>% kable(col.names = c("Race/Ethnicity","Number of Deaths"), caption="Number of Unarmed People Killed by Police by Race/Ethnicity")
```


```{r, echo=FALSE, warning=FALSE}
# HISTOGRAM ARMED BY RACE PER MILLION
race_count_armed <- per_million_counts(race_count_armed)
# Make a histogram
ggplot(na.omit(race_count_armed)) + geom_bar(aes(x=raceethnicity, y=per_million), stat = "identity", fill="#FF9999") + 
    theme(axis.text.x=element_text(angle=45,hjust=1,vjust=1), axis.line = element_line(colour = "black", size=.1),
          panel.background = element_blank()) +
    ggtitle('Unarmed People Killed by Police by Race/Ethnicity') +
    labs(x = 'Race/Ethnicity', y = '# killed (per million)')
```



***

# Final Analysis 
What did you learn about the data? 
How did you answer the questions? 
How can you justify your answers?
```{r}

```









